# *Introduction to Linear Regression*
- Linear regression is a powerful modeling technique that can be used to understand the relationship between a quantitative variable and one or more other variables, sometimes with the goal of making predictions. For example, linear regression can help us answer questions like:
    - What is the relationship between apartment size and rental price for NYC apartments?
    - Is a mother’s height a good predictor of their child’s adult height?


Equation of a line
y = mx + b 
- x and y represent variables, such as height and weight or hours of studying and quiz scores.
- b represents the y-intercept of the line. This is where the line intersects with the y-axis (a vertical line located at x = 0).
- m represents the slope. This controls how steep the line is. If we choose any two points on a line, the slope is the ratio between the vertical and horizontal distance between those points; this is often written as rise/run.

Finding the "Best" Line
- Depending on our ultimate goals and data, we might choose different criteria.
- However, a common choice for linear regression is *ordinary least squares (OLS)*.
- In simple OLS regression, we assume that the relationship between two variables *x* and *y* can be modeled as:
y = mx + b + error
- We define “best” as the line that minimizes the *total squared error* for all data points.
- This total squared error is called the *loss function* in machine learning.


Fitting a Linear Regression Model in Python
- There are a number of Python libraries that can be used to fit a linear regression, but we will use the library OLS.from_formula() function from statsmodels.api
- Suppose we have a dataset named body_measurements with columns height and weight. If we want to fit a model that can predict weight based on height, we can create the model as follows:
model = sm.OLS.from_formula('weight ~ height', data = body_measurements)
- We used the formula 'weight ~ height' because we want to predict weight (it is the outcome variable) using height as a predictor. Then, we can fit the model using .fit():
results = model.fit()
- Finally, we can inspect a summary of the results using print(results.summary()). For now, we’ll only look at the coefficients using results.params, but the full summary table is useful because it contains other important diagnostic information.
print(results.params)
- Output: This tells us that the best-fit intercept is -21.67, and the best-fit slope is 0.50.
Intercept   -21.67
height        0.50
dtype: float64

Using a Regression Model for Prediction
- Suppose that we have a dataset of heights and weights for 100 adults. We fit a linear regression and print the coefficients:
model = sm.OLS.from_formula('weight ~ height', data = body_measurements)
results = model.fit()
print(results.params)

Another example:
- Predicts test `score` using `hours_studied`. Print the coefficients of this model using `.params`.
- What is the predicted score for a student who spent 3 hours studying? Save the result as `pred_3hr` and print it out. Calculate your answer by plugging into the formula for a line (instead of using `.predict()`).
- What is the predicted score for a student who spent 5 hours studying? Use the `.predict()` method to calculate your answer and save it as `pred_5hr`, then print it out.

# Load libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import statsmodels.api as sm

# Read in the data
students = pd.read_csv('test_data.csv')

# Fit the model
model = sm.OLS.from_formula('score ~ hours_studied', students)
results = model.fit()
print(results.params)
# Print the model params

# Calculate and print `pred_3hr` here:
pred_3hr = results.params[1]*3 + results.params[0]
print(pred_3hr)
# Calculate and print `pred_5hr` here:
newdata = {'hours_studied':[5]}
pred_5hr = results.predict(newdata)
print(pred_5hr)








